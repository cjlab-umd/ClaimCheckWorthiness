{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec_model = KeyedVectors.load_word2vec_format('/home/rony/Downloads/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vec_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('all_sentences.csv', encoding='utf-8', index_col=False)\n",
    "crowd_sourced = pd.read_csv('crowdsourced.csv', encoding='utf-8', index_col=False)\n",
    "groundtruth = pd.read_csv('groundtruth.csv', encoding='utf-8', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'Speaker', 'Speaker_title', 'Speaker_party',\n",
       "       'Speaker_role', 'File_id', 'Length', 'Line_number', 'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'Speaker', 'Speaker_title', 'Speaker_party',\n",
       "       'File_id', 'Length', 'Line_number', 'Sentiment', 'Verdict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_sourced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'Speaker', 'Speaker_title', 'Speaker_party',\n",
       "       'File_id', 'Length', 'Line_number', 'Sentiment', 'Verdict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32072, 22501, 1032)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data), len(crowd_sourced), len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb20598dda0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEctJREFUeJzt3X+s3Xddx/Hny9XxU2jHLjDaaqs04EAN82ZMTYxhunVo6P5gSRfi6mzSRIe/jWyaWH7NQDBOF2GmsEpnyMYyNWtkMJsBIQY2dge4Mcbsdeh66WAXWyZKBApv/7if6qGfc3vbc+567ujzkZyc7/f9+XzPeX9z0r76/XFOU1VIkjTo+ybdgCRp5TEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1Fk16QZGdfbZZ9eGDRsm3YYkPaXcd999X6mqqaXmPWXDYcOGDczMzEy6DUl6Skny7ycyz9NKkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqTOU/Yb0qfahqs/MOkWnjT/9rZfnHQLklYYjxwkSR3DQZLUMRwkSR3DQZLUMRwkSZ0lwyHJ7iSPJ/nskLHfT1JJzm7rSXJ9ktkk9yc5b2DutiT722PbQP0nkzzQtrk+SZZr5yRJozmRI4f3ApuPLSZZD/wC8OhA+RJgU3vsAG5oc88CdgKvBM4HdiZZ07a5oc09ul33XpKkU2vJcKiqjwGHhgxdB/wBUAO1LcBNteBuYHWSc4CLgX1VdaiqDgP7gM1t7DlV9YmqKuAm4NLxdkmSNK6RrjkkeQ3wxar652OG1gIHBtbnWu149bkh9cXed0eSmSQz8/Pzo7QuSToBJx0OSZ4J/BHwx8OGh9RqhPpQVbWrqqaranpqasn/H1uSNKJRjhx+BNgI/HOSfwPWAZ9K8kIW/uW/fmDuOuDgEvV1Q+qSpAk66XCoqgeq6vlVtaGqNrDwF/x5VfUlYC9wRbtr6QLgiap6DLgTuCjJmnYh+iLgzjb2tSQXtLuUrgBuX6Z9kySN6ERuZb0Z+ATwkiRzSbYfZ/odwCPALPBu4NcBquoQ8Bbg3vZ4c6sB/BrwnrbNvwIfHG1XJEnLZclfZa2qy5cY3zCwXMBVi8zbDeweUp8BXr5UH5KkU8dvSEuSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOkuGQ5LdSR5P8tmB2juSfD7J/Un+PsnqgbFrkswmeTjJxQP1za02m+TqgfrGJPck2Z/k/UnOXM4dlCSdvBM5cngvsPmY2j7g5VX148C/ANcAJDkX2Aq8rG3zriRnJDkDeCdwCXAucHmbC/B24Lqq2gQcBraPtUeSpLEtGQ5V9THg0DG1f6yqI231bmBdW94C3FJV36iqLwCzwPntMVtVj1TVN4FbgC1JArwKuK1tvwe4dMx9kiSNaTmuOfwq8MG2vBY4MDA212qL1Z8HfHUgaI7WJUkTNFY4JPkj4AjwvqOlIdNqhPpi77cjyUySmfn5+ZNtV5J0gkYOhyTbgF8CXldVR/9CnwPWD0xbBxw8Tv0rwOokq46pD1VVu6pquqqmp6amRm1dkrSEkcIhyWbgDcBrqurrA0N7ga1JnpZkI7AJ+CRwL7Cp3Zl0JgsXrfe2UPkI8Nq2/Tbg9tF2RZK0XE7kVtabgU8AL0kyl2Q78JfADwD7knwmyV8BVNWDwK3A54APAVdV1bfbNYXXA3cCDwG3trmwEDK/m2SWhWsQNy7rHkqSTtqqpSZU1eVDyov+BV5V1wLXDqnfAdwxpP4IC3czSZJWCL8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqLBkOSXYneTzJZwdqZyXZl2R/e17T6klyfZLZJPcnOW9gm21t/v4k2wbqP5nkgbbN9Umy3DspSTo5J3Lk8F5g8zG1q4G7qmoTcFdbB7gE2NQeO4AbYCFMgJ3AK4HzgZ1HA6XN2TGw3bHvJUk6xZYMh6r6GHDomPIWYE9b3gNcOlC/qRbcDaxOcg5wMbCvqg5V1WFgH7C5jT2nqj5RVQXcNPBakqQJGfWawwuq6jGA9vz8Vl8LHBiYN9dqx6vPDalLkiZouS9ID7teUCPUh794siPJTJKZ+fn5EVuUJC1l1HD4cjslRHt+vNXngPUD89YBB5eorxtSH6qqdlXVdFVNT01Njdi6JGkpo4bDXuDoHUfbgNsH6le0u5YuAJ5op53uBC5KsqZdiL4IuLONfS3JBe0upSsGXkuSNCGrlpqQ5Gbg54Czk8yxcNfR24Bbk2wHHgUua9PvAF4NzAJfB64EqKpDSd4C3Nvmvbmqjl7k/jUW7oh6BvDB9pAkTdCS4VBVly8ydOGQuQVctcjr7AZ2D6nPAC9fqg9J0qnjN6QlSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSZ2xwiHJ7yR5MMlnk9yc5OlJNia5J8n+JO9Pcmab+7S2PtvGNwy8zjWt/nCSi8fbJUnSuEYOhyRrgd8Epqvq5cAZwFbg7cB1VbUJOAxsb5tsBw5X1YuB69o8kpzbtnsZsBl4V5IzRu1LkjS+cU8rrQKekWQV8EzgMeBVwG1tfA9waVve0tZp4xcmSavfUlXfqKovALPA+WP2JUkaw8jhUFVfBP4UeJSFUHgCuA/4alUdadPmgLVteS1woG17pM1/3mB9yDaSpAkY57TSGhb+1b8ReBHwLOCSIVPr6CaLjC1WH/aeO5LMJJmZn58/+aYlSSdknNNKPw98oarmq+pbwN8BPw2sbqeZANYBB9vyHLAeoI0/Fzg0WB+yzXepql1VNV1V01NTU2O0Lkk6nnHC4VHggiTPbNcOLgQ+B3wEeG2bsw24vS3vbeu08Q9XVbX61nY300ZgE/DJMfqSJI1p1dJThquqe5LcBnwKOAJ8GtgFfAC4JclbW+3GtsmNwN8kmWXhiGFre50Hk9zKQrAcAa6qqm+P2pckaXwjhwNAVe0Edh5TfoQhdxtV1f8Aly3yOtcC147TiyRp+fgNaUlSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHXGCockq5PcluTzSR5K8lNJzkqyL8n+9rymzU2S65PMJrk/yXkDr7Otzd+fZNu4OyVJGs+4Rw5/AXyoql4K/ATwEHA1cFdVbQLuausAlwCb2mMHcANAkrOAncArgfOBnUcDRZI0GSOHQ5LnAD8L3AhQVd+sqq8CW4A9bdoe4NK2vAW4qRbcDaxOcg5wMbCvqg5V1WFgH7B51L4kSeMb58jhh4F54K+TfDrJe5I8C3hBVT0G0J6f3+avBQ4MbD/XaovVO0l2JJlJMjM/Pz9G65Kk4xknHFYB5wE3VNUrgP/m/08hDZMhtTpOvS9W7aqq6aqanpqaOtl+JUknaJxwmAPmquqetn4bC2Hx5Xa6iPb8+MD89QPbrwMOHqcuSZqQkcOhqr4EHEjykla6EPgcsBc4esfRNuD2trwXuKLdtXQB8EQ77XQncFGSNe1C9EWtJkmakFVjbv8bwPuSnAk8AlzJQuDcmmQ78ChwWZt7B/BqYBb4eptLVR1K8hbg3jbvzVV1aMy+JEljGCscquozwPSQoQuHzC3gqkVeZzewe5xeJEnLx29IS5I6hoMkqTPuNQdp5XvjcyfdwZPrjU9MugN9D/LIQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSZ2xwyHJGUk+neQf2vrGJPck2Z/k/UnObPWntfXZNr5h4DWuafWHk1w8bk+SpPEsx5HDbwEPDay/HbiuqjYBh4Htrb4dOFxVLwaua/NIci6wFXgZsBl4V5IzlqEvSdKIxgqHJOuAXwTe09YDvAq4rU3ZA1zalre0ddr4hW3+FuCWqvpGVX0BmAXOH6cvSdJ4xj1y+HPgD4DvtPXnAV+tqiNtfQ5Y25bXAgcA2vgTbf7/1Yds812S7Egyk2Rmfn5+zNYlSYsZORyS/BLweFXdN1geMrWWGDveNt9drNpVVdNVNT01NXVS/UqSTtyqMbb9GeA1SV4NPB14DgtHEquTrGpHB+uAg23+HLAemEuyCngucGigftTgNpKkCRj5yKGqrqmqdVW1gYULyh+uqtcBHwFe26ZtA25vy3vbOm38w1VVrb613c20EdgEfHLUviRJ4xvnyGExbwBuSfJW4NPAja1+I/A3SWZZOGLYClBVDya5FfgccAS4qqq+/ST0JUk6QcsSDlX1UeCjbfkRhtxtVFX/A1y2yPbXAtcuRy+SpPH5DWlJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUufJ+G9CJWnZ/NieH5t0C0+qB7Y9MOkWhvLIQZLUGTkckqxP8pEkDyV5MMlvtfpZSfYl2d+e17R6klyfZDbJ/UnOG3itbW3+/iTbxt8tSdI4xjlyOAL8XlX9KHABcFWSc4GrgbuqahNwV1sHuATY1B47gBtgIUyAncArgfOBnUcDRZI0GSOHQ1U9VlWfastfAx4C1gJbgD1t2h7g0ra8BbipFtwNrE5yDnAxsK+qDlXVYWAfsHnUviRJ41uWaw5JNgCvAO4BXlBVj8FCgADPb9PWAgcGNptrtcXqkqQJGTsckjwb+Fvgt6vqP483dUitjlMf9l47kswkmZmfnz/5ZiVJJ2SscEjy/SwEw/uq6u9a+cvtdBHt+fFWnwPWD2y+Djh4nHqnqnZV1XRVTU9NTY3TuiTpOMa5WynAjcBDVfVnA0N7gaN3HG0Dbh+oX9HuWroAeKKddroTuCjJmnYh+qJWkyRNyDhfgvsZ4JeBB5J8ptX+EHgbcGuS7cCjwGVt7A7g1cAs8HXgSoCqOpTkLcC9bd6bq+rQGH1JksY0cjhU1T8x/HoBwIVD5hdw1SKvtRvYPWovkqTl5TekJUkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEmdFRMOSTYneTjJbJKrJ92PJJ3OVkQ4JDkDeCdwCXAucHmScyfblSSdvlZEOADnA7NV9UhVfRO4Bdgy4Z4k6bS1UsJhLXBgYH2u1SRJE7Bq0g00GVKrblKyA9jRVv8rycNPaleTdTbwlVPxRnn7qXiX08op++wAeNOwPz4awyn9/PIrp/zz+6ETmbRSwmEOWD+wvg44eOykqtoF7DpVTU1Skpmqmp50Hzp5fnZPbX5+C1bKaaV7gU1JNiY5E9gK7J1wT5J02loRRw5VdSTJ64E7gTOA3VX14ITbkqTT1ooIB4CqugO4Y9J9rCCnxemz71F+dk9tfn5AqrrrvpKk09xKueYgSVpBDAdJUmfFXHOQpFMtyUtZ+DWGtSx8t+ogsLeqHppoYyuARw4rWJJnT7oH6XtVkjew8FM9AT7Jwi31AW72xz+9IL2iJXm0qn5w0n1oNEmurKq/nnQfGi7JvwAvq6pvHVM/E3iwqjZNprOVwdNKE5bkdxcbAjxyeGp7E2A4rFzfAV4E/Psx9XPa2GnNcJi8PwHeARwZMuZpvxUuyf2LDQEvOJW96KT9NnBXkv38/w9//iDwYuD1E+tqhfC00oQl+TjwG1V135CxA1W1fshmWiGSfBm4GDh87BDw8ap60anvSicqyfex8F8GrGXhM5sD7q2qb0+0sRXAI4fJuxL4j8FCkhdW1ZeA0/7Hv54C/gF4dlV95tiBJB899e3oZFTVd4C7J93HSuSRwwqU5FNVdd6k+5B0+vKc9srkD/RLmijDYWV696QbkHR687SSJKnjkYMkqWM4SJI6hoMkqWM4SJI6hoMkqfO/JFDpwHsuMT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb253c37b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd_sourced.Verdict.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    14685\n",
       " 1     5413\n",
       " 0     2403\n",
       "Name: Verdict, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_sourced.Verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>You know, I saw a movie - \"Crocodile Dundee.\"</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>We're consuming 50 percent of the world's coca...</td>\n",
       "      <td>Michael Dukakis</td>\n",
       "      <td>Governor</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0           26      You know, I saw a movie - \"Crocodile Dundee.\"   \n",
       "1           80  We're consuming 50 percent of the world's coca...   \n",
       "\n",
       "           Speaker   Speaker_title Speaker_party         File_id  Length  \\\n",
       "0      George Bush  Vice President    REPUBLICAN  1988-09-25.txt       9   \n",
       "1  Michael Dukakis        Governor      DEMOCRAT  1988-09-25.txt       8   \n",
       "\n",
       "   Line_number  Sentiment  Verdict  \n",
       "0           26   0.000000        0  \n",
       "1           80  -0.740979        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = groundtruth.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15638</td>\n",
       "      <td>So that pledge isn't realistic, and I think th...</td>\n",
       "      <td>Michael Dukakis</td>\n",
       "      <td>Governor</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1988-10-13.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12568</td>\n",
       "      <td>And you cannot fight a victory for Communism o...</td>\n",
       "      <td>Richard M. Nixon</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1960-10-21.txt</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10464</td>\n",
       "      <td>It's our job to fix the problem.</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>Senator</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2008-10-07.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.433056</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7540</td>\n",
       "      <td>I'm asking for your vote.</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2004-10-13.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>1126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13144</td>\n",
       "      <td>Then I believe that we should move full time o...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-10-13.txt</td>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0        15638  So that pledge isn't realistic, and I think th...   \n",
       "1        12568  And you cannot fight a victory for Communism o...   \n",
       "2        10464                   It's our job to fix the problem.   \n",
       "3         7540                          I'm asking for your vote.   \n",
       "4        13144  Then I believe that we should move full time o...   \n",
       "\n",
       "            Speaker   Speaker_title Speaker_party         File_id  Length  \\\n",
       "0   Michael Dukakis        Governor      DEMOCRAT  1988-10-13.txt      22   \n",
       "1  Richard M. Nixon  Vice President    REPUBLICAN  1960-10-21.txt      23   \n",
       "2       John McCain         Senator    REPUBLICAN  2008-10-07.txt       7   \n",
       "3    George W. Bush       President    REPUBLICAN  2004-10-13.txt       5   \n",
       "4   John F. Kennedy         Senator      DEMOCRAT  1960-10-13.txt      19   \n",
       "\n",
       "   Line_number  Sentiment  Verdict  \n",
       "0          170   0.000000       -1  \n",
       "1           76   0.000000       -1  \n",
       "2           63  -0.433056       -1  \n",
       "3         1126   0.000000       -1  \n",
       "4           93   0.000000       -1  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([crowd_sourced, groundtruth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23533, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = [text_to_wordlist(text).split() for text in data[\"Text\"].values.tolist()]\n",
    "labels = data[\"Verdict\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23533"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes', 'i', 'voted', 'for', 'it', 'supported', 'it']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: -1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize word2id and label2id dictionaries that will be used to encode words and labels\n",
    "word2id = dict()\n",
    "label2id = dict()\n",
    "\n",
    "max_words = 0 # maximum number of words in a sentence\n",
    "\n",
    "# Construction of word2id dict\n",
    "for sentence in input_sentences:\n",
    "    for word in sentence:\n",
    "        # Add words to word2id dict if not exist\n",
    "        if word.lower() not in word2id:\n",
    "            word2id[word.lower()] = len(word2id)\n",
    "    # If length of the sentence is greater than max_words, update max_words\n",
    "    if len(sentence) > max_words:\n",
    "        max_words = len(sentence)\n",
    "        \n",
    "word2id['_unk_'] = len(word2id) + 1\n",
    "# Construction of label2id and id2label dicts\n",
    "label2id = {l: i for i, l in enumerate(set(labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11955"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11955"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id['_unk_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.sample(range(0, len(input_sentences)), 1000)\n",
    "for idx in random_index:\n",
    "    sent = input_sentences[idx]\n",
    "    if len(sent) <= 10:\n",
    "        unk_count = 1\n",
    "    elif len(sent) > 10 and len(sent) <= 50:\n",
    "        unk_count = random.randint(1,2)\n",
    "    else:\n",
    "        unk_count = random.randint(1,3)\n",
    "    unk_idx = random.sample(range(0, len(sent)), unk_count)\n",
    "    for _idx in unk_idx:\n",
    "        sent[_idx] = '_unk_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('fact_vocab.p', 'wb') as fp:\n",
    "    pickle.dump(word2id, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (23533, 163)\n",
      "Shape of Y: (23533, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Encode input words and labels\n",
    "X = [[word2id[word.lower()] for word in sentence] for sentence in input_sentences]\n",
    "Y = [label2id[label] for label in labels]\n",
    "\n",
    "# Apply Padding to X\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, max_words)\n",
    "\n",
    "# Convert Y to numpy array\n",
    "Y = keras.utils.to_categorical(Y, num_classes=len(label2id), dtype='float32')\n",
    "\n",
    "# Print shapes\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (20000, 163)\n",
      "Shape of Y: (20000, 3)\n",
      "Shape of X_test: (3533, 163)\n",
      "Shape of Y_test: (3533, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test = X[20000:]\n",
    "X = X[:20000]\n",
    "Y_test = Y[20000:]\n",
    "Y = Y[:20000]\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of Y_test: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 163)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 163, 100)     1195600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 163, 100)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 163, 200)     160800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 163, 200)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 163, 1)       201         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 163)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 163)          0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            303         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,377,004\n",
      "Trainable params: 1,377,004\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # The dimension of word embeddings\n",
    "\n",
    "# Define input tensor\n",
    "sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
    "\n",
    "# Word embedding layer\n",
    "embedded_inputs =keras.layers.Embedding(len(word2id) + 1,\n",
    "                                        embedding_dim,\n",
    "                                        input_length=max_words)(sequence_input)\n",
    "\n",
    "# Apply dropout to prevent overfitting\n",
    "embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
    "\n",
    "# Apply Bidirectional LSTM over embedded inputs\n",
    "lstm_outs = keras.layers.wrappers.Bidirectional(\n",
    "    keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
    ")(embedded_inputs)\n",
    "\n",
    "# Apply dropout to LSTM outputs to prevent overfitting\n",
    "lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
    "\n",
    "# Attention Mechanism - Generate attention vectors\n",
    "input_dim = int(lstm_outs.shape[2])\n",
    "permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
    "attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
    "attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
    "attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
    "attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
    "\n",
    "# Last layer: fully connected with softmax activation\n",
    "fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
    "output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
    "\n",
    "# Finally building model\n",
    "model = keras.Model(inputs=[sequence_input], outputs=output)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 69s 4ms/step - loss: 0.7194 - accuracy: 0.7110 - val_loss: 0.5668 - val_accuracy: 0.7675\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 69s 4ms/step - loss: 0.5020 - accuracy: 0.8027 - val_loss: 0.5228 - val_accuracy: 0.7860\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 63s 3ms/step - loss: 0.4016 - accuracy: 0.8455 - val_loss: 0.5342 - val_accuracy: 0.7905\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 62s 3ms/step - loss: 0.3235 - accuracy: 0.8806 - val_loss: 0.6006 - val_accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 57s 3ms/step - loss: 0.2640 - accuracy: 0.9047 - val_loss: 0.6726 - val_accuracy: 0.7775\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 62s 3ms/step - loss: 0.2206 - accuracy: 0.9217 - val_loss: 0.7175 - val_accuracy: 0.7630\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 59s 3ms/step - loss: 0.1837 - accuracy: 0.9355 - val_loss: 0.7908 - val_accuracy: 0.7685\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 59s 3ms/step - loss: 0.1553 - accuracy: 0.9454 - val_loss: 0.8688 - val_accuracy: 0.7550\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 57s 3ms/step - loss: 0.1336 - accuracy: 0.9518 - val_loss: 0.9844 - val_accuracy: 0.7410\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 61s 3ms/step - loss: 0.1118 - accuracy: 0.9607 - val_loss: 1.0809 - val_accuracy: 0.7505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd89d8cab90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model 10 iterations\n",
    "model.fit(X, Y, epochs=10, batch_size=64, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Model\n",
    "model.save(\"fact_checking_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 163)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 163, 100)     1195600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 163, 100)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 163, 200)     160800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 163, 200)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 163, 1)       201         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 163)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 163)          0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            303         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,377,004\n",
      "Trainable params: 1,377,004\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Loading Model\n",
    "from keras.models import load_model\n",
    "model = load_model('fact_checking_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "y_pred = pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=['UFS', 'FS', 'NFS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499640656119635"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_test, y_pred, average='weighted')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         UFS       0.44      0.32      0.37       368\n",
      "          FS       0.63      0.65      0.64       816\n",
      "         NFS       0.84      0.87      0.85      2349\n",
      "\n",
      "    accuracy                           0.76      3533\n",
      "   macro avg       0.64      0.61      0.62      3533\n",
      "weighted avg       0.75      0.76      0.75      3533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_precision_per_fold = []\n",
    "macro_recall_per_fold = []\n",
    "macro_f1_per_fold = []\n",
    "micro_precision_per_fold = []\n",
    "micro_recall_per_fold = []\n",
    "micro_f1_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_no = 1\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = buildmodel()\n",
    "    model.fit(X[train], Y[train], epochs=10, batch_size=64, verbose=0)\n",
    "    pred = model.predict(X[test])\n",
    "    y_pred = pred.argmax(axis=-1)\n",
    "    Y_test = Y[test].argmax(axis=-1)\n",
    "    scores = precision_recall_fscore_support(Y_test, y_pred, average='macro')\n",
    "    macro_precision_per_fold.append(scores[0])\n",
    "    macro_recall_per_fold.append(scores[1])\n",
    "    macro_f1_per_fold.append(scores[2])\n",
    "    scores = precision_recall_fscore_support(Y_test, y_pred, average='micro')\n",
    "    micro_precision_per_fold.append(scores[0])\n",
    "    micro_recall_per_fold.append(scores[1])\n",
    "    micro_f1_per_fold.append(scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236142556147392"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(macro_precision_per_fold)/len(macro_precision_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6112308030793936"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(macro_recall_per_fold)/len(macro_recall_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7480980258263885"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(micro_precision_per_fold)/len(micro_precision_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7480980258263885"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(micro_recall_per_fold)/len(micro_recall_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    embedding_dim = 100 # The dimension of word embeddings\n",
    "\n",
    "    # Define input tensor\n",
    "    sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
    "\n",
    "    # Word embedding layer\n",
    "    embedded_inputs =keras.layers.Embedding(len(word2id) + 1,\n",
    "                                            embedding_dim,\n",
    "                                            input_length=max_words)(sequence_input)\n",
    "\n",
    "    # Apply dropout to prevent overfitting\n",
    "    embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
    "\n",
    "    # Apply Bidirectional LSTM over embedded inputs\n",
    "    lstm_outs = keras.layers.wrappers.Bidirectional(\n",
    "        keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
    "    )(embedded_inputs)\n",
    "\n",
    "    # Apply dropout to LSTM outputs to prevent overfitting\n",
    "    lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
    "\n",
    "    # Attention Mechanism - Generate attention vectors\n",
    "    input_dim = int(lstm_outs.shape[2])\n",
    "    permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
    "    attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
    "    attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
    "    attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
    "    attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
    "\n",
    "    # Last layer: fully connected with softmax activation\n",
    "    fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
    "    output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
    "\n",
    "    # Finally building model\n",
    "    model = keras.Model(inputs=[sequence_input], outputs=output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "    # Print model summary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator= KerasRegressor(build_fn=buildmodel, epochs=10, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold= RepeatedKFold(n_splits=5, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= cross_val_score(estimator, X, Y, cv=kfold, n_jobs=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.142590797819267"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15816937, -1.12107016, -1.14735263, -1.12824547, -1.15811636])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 661, 1560)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Y_test).count(0), list(Y_test).count(1), list(Y_test).count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 1, 1,\n",
       "       2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2,\n",
       "       2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2,\n",
       "       2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the model to get attention vectors as well as label prediction\n",
    "model_with_attentions = keras.Model(inputs=model.input,\n",
    "                                    outputs=[model.output, \n",
    "                                             model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'i' in word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['announcer',\n",
       " ':',\n",
       " 'live',\n",
       " 'from',\n",
       " 'the',\n",
       " 'gaillard',\n",
       " 'center',\n",
       " 'in',\n",
       " 'charleston',\n",
       " 'south',\n",
       " 'carolina',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'cbs',\n",
       " 'news',\n",
       " 'democratic',\n",
       " 'debate']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample = text_to_wordlist(sample_text).split()\n",
    "tokenized_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0, 10177,  1530,   448,   137,    40, 11798,  7992,    38,\n",
       "        11798,  2118,  3603,    54,    45,    40,  8270,  2232,   265,\n",
       "         1684]], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for word in tokenized_sample:\n",
    "    if word.lower() in word2id:\n",
    "        tmp.append(word2id[word.lower()])\n",
    "    else:\n",
    "        tmp.append(word2id['_unk_'])\n",
    "encoded_samples = [tmp]\n",
    "\n",
    "# Padding\n",
    "encoded_samples = keras.preprocessing.sequence.pad_sequences(encoded_samples, maxlen=max_words)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[7.8109838e-03, 8.6440006e-05, 9.9210256e-01]], dtype=float32),\n",
       " array([[0.00105436, 0.00103967, 0.00104715, 0.00106706, 0.0010923 ,\n",
       "         0.00111766, 0.00113956, 0.00115584, 0.00116562, 0.00116908,\n",
       "         0.00116715, 0.00116121, 0.00115275, 0.00114323, 0.00113382,\n",
       "         0.00112544, 0.00111865, 0.00111371, 0.00111066, 0.00110934,\n",
       "         0.00110945, 0.00111064, 0.00111254, 0.0011148 , 0.0011171 ,\n",
       "         0.00111922, 0.00112098, 0.00112231, 0.00112317, 0.00112359,\n",
       "         0.00112363, 0.00112339, 0.00112295, 0.0011224 , 0.00112183,\n",
       "         0.00112129, 0.00112083, 0.00112048, 0.00112024, 0.00112011,\n",
       "         0.00112008, 0.00112013, 0.00112023, 0.00112036, 0.0011205 ,\n",
       "         0.00112063, 0.00112075, 0.00112085, 0.00112091, 0.00112095,\n",
       "         0.00112097, 0.00112096, 0.00112094, 0.00112091, 0.00112088,\n",
       "         0.00112084, 0.00112082, 0.00112079, 0.00112078, 0.00112077,\n",
       "         0.00112077, 0.00112077, 0.00112078, 0.00112079, 0.0011208 ,\n",
       "         0.00112081, 0.00112083, 0.00112084, 0.00112085, 0.00112085,\n",
       "         0.00112086, 0.00112087, 0.00112087, 0.00112088, 0.00112089,\n",
       "         0.00112089, 0.0011209 , 0.00112091, 0.00112092, 0.00112093,\n",
       "         0.00112094, 0.00112096, 0.00112097, 0.00112099, 0.00112101,\n",
       "         0.00112103, 0.00112105, 0.00112108, 0.00112111, 0.00112114,\n",
       "         0.00112117, 0.00112121, 0.00112125, 0.00112129, 0.00112134,\n",
       "         0.00112139, 0.00112145, 0.00112151, 0.00112158, 0.00112166,\n",
       "         0.00112175, 0.00112185, 0.00112195, 0.00112207, 0.00112221,\n",
       "         0.00112236, 0.00112252, 0.00112271, 0.00112292, 0.00112316,\n",
       "         0.00112343, 0.00112374, 0.00112408, 0.00112448, 0.00112494,\n",
       "         0.00112546, 0.00112607, 0.00112677, 0.0011276 , 0.00112857,\n",
       "         0.00112971, 0.00113108, 0.00113273, 0.00113472, 0.00113715,\n",
       "         0.00114017, 0.00114394, 0.00114873, 0.00115489, 0.00116296,\n",
       "         0.00117372, 0.00118839, 0.0012089 , 0.00123839, 0.00128218,\n",
       "         0.00134966, 0.00145817, 0.00164162, 0.00197091, 0.0026062 ,\n",
       "         0.00393917, 0.00697437, 0.01414857, 0.03033285, 0.06291526,\n",
       "         0.04647572, 0.03350548, 0.01790348, 0.00925985, 0.00873381,\n",
       "         0.01008155, 0.01370601, 0.01559058, 0.01723238, 0.02126163,\n",
       "         0.05755361, 0.02746699, 0.03876561, 0.04744058, 0.0443935 ,\n",
       "         0.16853242, 0.05646457, 0.0862787 ]], dtype=float32)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_attentions.predict(encoded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Select random samples to illustrate\n",
    "sample_text = 'ANNOUNCER: Live from the Gaillard Center in Charleston, South Carolina, this is the CBS News Democratic debate.'\n",
    "wrod_lists = sample_text.split()\n",
    "\n",
    "# Encode samples\n",
    "tokenized_sample = text_to_wordlist(sample_text).split()\n",
    "tmp = []\n",
    "for word in tokenized_sample:\n",
    "    if word.lower() in word2id:\n",
    "        tmp.append(word2id[word.lower()])\n",
    "    else:\n",
    "        tmp.append(word2id['_unk_'])\n",
    "encoded_samples = [tmp]\n",
    "\n",
    "# Padding\n",
    "encoded_samples = keras.preprocessing.sequence.pad_sequences(encoded_samples, maxlen=max_words)\n",
    "\n",
    "# Make predictions\n",
    "label_probs, attentions = model_with_attentions.predict(encoded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8109838e-03, 8.6440006e-05, 9.9210256e-01]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00105436, 0.00103967, 0.00104715, 0.00106706, 0.0010923 ,\n",
       "        0.00111766, 0.00113956, 0.00115584, 0.00116562, 0.00116908,\n",
       "        0.00116715, 0.00116121, 0.00115275, 0.00114323, 0.00113382,\n",
       "        0.00112544, 0.00111865, 0.00111371, 0.00111066, 0.00110934,\n",
       "        0.00110945, 0.00111064, 0.00111254, 0.0011148 , 0.0011171 ,\n",
       "        0.00111922, 0.00112098, 0.00112231, 0.00112317, 0.00112359,\n",
       "        0.00112363, 0.00112339, 0.00112295, 0.0011224 , 0.00112183,\n",
       "        0.00112129, 0.00112083, 0.00112048, 0.00112024, 0.00112011,\n",
       "        0.00112008, 0.00112013, 0.00112023, 0.00112036, 0.0011205 ,\n",
       "        0.00112063, 0.00112075, 0.00112085, 0.00112091, 0.00112095,\n",
       "        0.00112097, 0.00112096, 0.00112094, 0.00112091, 0.00112088,\n",
       "        0.00112084, 0.00112082, 0.00112079, 0.00112078, 0.00112077,\n",
       "        0.00112077, 0.00112077, 0.00112078, 0.00112079, 0.0011208 ,\n",
       "        0.00112081, 0.00112083, 0.00112084, 0.00112085, 0.00112085,\n",
       "        0.00112086, 0.00112087, 0.00112087, 0.00112088, 0.00112089,\n",
       "        0.00112089, 0.0011209 , 0.00112091, 0.00112092, 0.00112093,\n",
       "        0.00112094, 0.00112096, 0.00112097, 0.00112099, 0.00112101,\n",
       "        0.00112103, 0.00112105, 0.00112108, 0.00112111, 0.00112114,\n",
       "        0.00112117, 0.00112121, 0.00112125, 0.00112129, 0.00112134,\n",
       "        0.00112139, 0.00112145, 0.00112151, 0.00112158, 0.00112166,\n",
       "        0.00112175, 0.00112185, 0.00112195, 0.00112207, 0.00112221,\n",
       "        0.00112236, 0.00112252, 0.00112271, 0.00112292, 0.00112316,\n",
       "        0.00112343, 0.00112374, 0.00112408, 0.00112448, 0.00112494,\n",
       "        0.00112546, 0.00112607, 0.00112677, 0.0011276 , 0.00112857,\n",
       "        0.00112971, 0.00113108, 0.00113273, 0.00113472, 0.00113715,\n",
       "        0.00114017, 0.00114394, 0.00114873, 0.00115489, 0.00116296,\n",
       "        0.00117372, 0.00118839, 0.0012089 , 0.00123839, 0.00128218,\n",
       "        0.00134966, 0.00145817, 0.00164162, 0.00197091, 0.0026062 ,\n",
       "        0.00393917, 0.00697437, 0.01414857, 0.03033285, 0.06291526,\n",
       "        0.04647572, 0.03350548, 0.01790348, 0.00925985, 0.00873381,\n",
       "        0.01008155, 0.01370601, 0.01559058, 0.01723238, 0.02126163,\n",
       "        0.05755361, 0.02746699, 0.03876561, 0.04744058, 0.0443935 ,\n",
       "        0.16853242, 0.05646457, 0.0862787 ]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_probs = {id2label[_id]: prob for (label, _id), prob in zip(label2id.items(),label_probs[0])}\n",
    "\n",
    "# Get word attentions using attenion vector\n",
    "token_attention_dic = {}\n",
    "max_score = 0.0\n",
    "min_score = 0.0\n",
    "for token, attention_score in zip(tokenized_sample, attentions[0][-len(tokenized_sample):]):\n",
    "    token_attention_dic[token] = math.sqrt(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 0.70434064, 0: 0.29564035, 1: 1.909118e-05}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 0.20088818370590472,\n",
       " 'candidates': 0.4196677925214949,\n",
       " 'for': 0.337813065287552,\n",
       " 'here': 0.17001260878105995,\n",
       " 'nomination': 0.29148494077293763,\n",
       " 'presidential': 0.2884038044392536,\n",
       " 'seven': 0.29913532448648184,\n",
       " 'the': 0.3368980735633713}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attention_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention2color(attention_score):\n",
    "    if attention_score > 0.0 and attention_score <= 0.10:\n",
    "        return \"#ffffff\"\n",
    "    elif attention_score > 0.10 and attention_score <= 0.20:\n",
    "        return \"#ffe6e6\"\n",
    "    elif attention_score > 0.20 and attention_score <= 0.30:\n",
    "        return \"#ffcccc\"\n",
    "    elif attention_score > 0.30 and attention_score <= 0.40:\n",
    "        return \"#ffb3b3\"\n",
    "    elif attention_score > 0.40 and attention_score <= 0.50:\n",
    "        return \"#ff9999\"\n",
    "    elif attention_score > 0.50 and attention_score <= 0.60:\n",
    "        return \"#ff8080\"\n",
    "    elif attention_score > 0.60 and attention_score <= 0.70:\n",
    "        return \"#ff6666\"\n",
    "    elif attention_score > 0.70 and attention_score <= 0.80:\n",
    "        return \"#ff4d4d\"\n",
    "    elif attention_score > 0.80 and attention_score <= 0.90:\n",
    "        return \"#ff3333\"\n",
    "    else:\n",
    "        return \"#ff1a1a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size: large'><b>Text:  </b><span style='background-color:#ffe6e6;'>here <span> <span style='background-color:#ffcccc;'>are <span> <span style='background-color:#ffb3b3;'>the <span> <span style='background-color:#ffcccc;'>seven <span> <span style='background-color:#ff9999;'>candidates <span> <span style='background-color:#ffb3b3;'>for <span> <span style='background-color:#ffcccc;'>presidential <span> <span style='background-color:#ffcccc;'>nomination <span> </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build HTML String to viualize attentions\n",
    "html_text = \"<p style='font-size: large'><b>Text:  </b>\"\n",
    "for token, attention in token_attention_dic.items():\n",
    "    html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention),\n",
    "                                                                        token)\n",
    "html_text += \"</p>\"\n",
    "# Display text enriched with attention scores \n",
    "display(HTML(html_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p style='font-size: large'><b>Text:  </b><span style='background-color:#ffffff;'>bernie <span> <span style='background-color:#ffffff;'>and <span> <span style='background-color:#ffffff;'>i <span> <span style='background-color:#ffffff;'>both <span> <span style='background-color:#ffffff;'>want <span> <span style='background-color:#ffe6e6;'>to <span> <span style='background-color:#ffffff;'>see <span> <span style='background-color:#ffffff;'>universal <span> <span style='background-color:#ffffff;'>health <span> <span style='background-color:#ffffff;'>care <span> <span style='background-color:#ffffff;'>but <span> <span style='background-color:#ffffff;'>plan <span> <span style='background-color:#ffffff;'>does <span> <span style='background-color:#ffffff;'>not <span> <span style='background-color:#ffffff;'>explain <span> <span style='background-color:#ffffff;'>how <span> <span style='background-color:#ffffff;'>get <span> <span style='background-color:#ffffff;'>there <span> <span style='background-color:#ffffff;'>show <span> <span style='background-color:#ffffff;'>we <span> <span style='background-color:#ffe6e6;'>are <span> <span style='background-color:#ffe6e6;'>going <span> <span style='background-color:#ffffff;'>enough <span> <span style='background-color:#ffffff;'>allies <span> <span style='background-color:#ffffff;'>into <span> <span style='background-color:#ff9999;'>it <span> <span style='background-color:#ffffff;'>about <span> <span style='background-color:#ffcccc;'>pay <span> <span style='background-color:#ffb3b3;'>for <span> </p>\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entire record is such that the unemployment has not been reduced in this country.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ffffff;'>the <span> <span style='background-color:#ffe6e6;'>entire <span> <span style='background-color:#ffe6e6;'>record <span> <span style='background-color:#ffffff;'>is <span> <span style='background-color:#ffffff;'>such <span> <span style='background-color:#ffe6e6;'>that <span> <span style='background-color:#ffe6e6;'>unemployment <span> <span style='background-color:#ffcccc;'>has <span> <span style='background-color:#ffe6e6;'>not <span> <span style='background-color:#ffcccc;'>been <span> <span style='background-color:#ff8080;'>reduced <span> <span style='background-color:#ff9999;'>in <span> <span style='background-color:#ffb3b3;'>this <span> <span style='background-color:#ff9999;'>country <span> </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e047892e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Select random samples to illustrate\n",
    "sample_text = random.choice(groundtruth[\"Text\"].values.tolist())\n",
    "print(sample_text)\n",
    "\n",
    "# Encode samples\n",
    "tokenized_sample = text_to_wordlist(sample_text).split()\n",
    "tmp = []\n",
    "for word in tokenized_sample:\n",
    "    if word.lower() in word2id:\n",
    "        tmp.append(word2id[word.lower()])\n",
    "    else:\n",
    "        tmp.append(word2id['_unk'])\n",
    "encoded_samples = [tmp]\n",
    "# Padding\n",
    "encoded_samples = keras.preprocessing.sequence.pad_sequences(encoded_samples, maxlen=max_words)\n",
    "\n",
    "# Make predictions\n",
    "label_probs, attentions = model_with_attentions.predict(encoded_samples)\n",
    "label_probs = {id2label[_id]: prob for (label, _id), prob in zip(label2id.items(),label_probs[0])}\n",
    "\n",
    "# Get word attentions using attenion vector\n",
    "token_attention_dic = {}\n",
    "max_score = 0.0\n",
    "min_score = 0.0\n",
    "for token, attention_score in zip(tokenized_sample, attentions[0][-len(tokenized_sample):]):\n",
    "    token_attention_dic[token] = math.sqrt(attention_score)\n",
    "\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "    \n",
    "def attention2color(attention_score):\n",
    "    if attention_score > 0.0 and attention_score <= 0.10:\n",
    "        return \"#ffffff\"\n",
    "    elif attention_score > 0.10 and attention_score <= 0.20:\n",
    "        return \"#ffe6e6\"\n",
    "    elif attention_score > 0.20 and attention_score <= 0.30:\n",
    "        return \"#ffcccc\"\n",
    "    elif attention_score > 0.30 and attention_score <= 0.40:\n",
    "        return \"#ffb3b3\"\n",
    "    elif attention_score > 0.40 and attention_score <= 0.50:\n",
    "        return \"#ff9999\"\n",
    "    elif attention_score > 0.50 and attention_score <= 0.60:\n",
    "        return \"#ff8080\"\n",
    "    elif attention_score > 0.60 and attention_score <= 0.70:\n",
    "        return \"#ff6666\"\n",
    "    elif attention_score > 0.70 and attention_score <= 0.80:\n",
    "        return \"#ff4d4d\"\n",
    "    elif attention_score > 0.80 and attention_score <= 0.90:\n",
    "        return \"#ff3333\"\n",
    "    else:\n",
    "        return \"#ff1a1a\"\n",
    "#     r = 255 - int(attention_score * 255)\n",
    "#     color = rgb_to_hex((255, r, r))\n",
    "#     return str(color)\n",
    "\n",
    "    \n",
    "# Build HTML String to viualize attentions\n",
    "html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
    "for token, attention in token_attention_dic.items():\n",
    "    html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention),\n",
    "                                                                        token)\n",
    "html_text += \"</p>\"\n",
    "# Display text enriched with attention scores \n",
    "display(HTML(html_text))\n",
    "\n",
    "# PLOT EMOTION SCORES\n",
    "emotions = [label for label, _ in label_probs.items()]\n",
    "scores = [score for _, score in label_probs.items()]\n",
    "plt.figure(figsize=(5,2))\n",
    "plt.bar(np.arange(len(emotions)), scores, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan', \"purple\"])\n",
    "plt.xticks(np.arange(len(emotions)), emotions)\n",
    "plt.ylabel('Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = [text_to_wordlist(text).split() for text in crowd_sourced[\"Text\"].values.tolist()]\n",
    "labels = crowd_sourced[\"Verdict\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: -1}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize word2id and label2id dictionaries that will be used to encode words and labels\n",
    "word2id = dict()\n",
    "label2id = dict()\n",
    "\n",
    "max_words = 0 # maximum number of words in a sentence\n",
    "\n",
    "# Construction of word2id dict\n",
    "for sentence in input_sentences:\n",
    "    for word in sentence:\n",
    "        # Add words to word2id dict if not exist\n",
    "        if word.lower() not in word2id:\n",
    "            word2id[word.lower()] = len(word2id)\n",
    "    # If length of the sentence is greater than max_words, update max_words\n",
    "    if len(sentence) > max_words:\n",
    "        max_words = len(sentence)\n",
    "    \n",
    "# Construction of label2id and id2label dicts\n",
    "label2id = {l: i for i, l in enumerate(set(labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (22501, 163)\n",
      "Shape of Y: (22501, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Encode input words and labels\n",
    "X = [[word2id[word.lower()] for word in sentence] for sentence in input_sentences]\n",
    "Y = [label2id[label] for label in labels]\n",
    "\n",
    "# Apply Padding to X\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, max_words)\n",
    "\n",
    "# Convert Y to numpy array\n",
    "Y = keras.utils.to_categorical(Y, num_classes=len(label2id), dtype='float32')\n",
    "\n",
    "# Print shapes\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (20000, 163)\n",
      "Shape of Y: (20000, 3)\n",
      "Shape of X_test: (2501, 163)\n",
      "Shape of Y_test: (2501, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test = X[20000:]\n",
    "X = X[:20000]\n",
    "Y_test = Y[20000:]\n",
    "Y = Y[:20000]\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of Y_test: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1155\n"
     ]
    }
   ],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word2id))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, 300))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2vec_model.vocab:\n",
    "        embedding_matrix[i] = w2vec_model.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11798"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 163)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 163, 300)     3539400     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 163, 300)     0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 163, 600)     1442400     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 163, 600)     0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 163, 1)       601         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 163)          0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 163)          0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 600)          0           dropout_10[0][0]                 \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 300)          180300      dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 3)            903         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,163,604\n",
      "Trainable params: 5,163,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300 # The dimension of word embeddings\n",
    "\n",
    "# Define input tensor\n",
    "sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
    "\n",
    "# Word embedding layer\n",
    "embedded_inputs =keras.layers.Embedding(len(word2id) + 1,\n",
    "                                        embedding_dim,\n",
    "                                        embeddings_initializer=Constant(embedding_matrix),\n",
    "                                        input_length=max_words)(sequence_input)\n",
    "\n",
    "# Apply dropout to prevent overfitting\n",
    "embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
    "\n",
    "# Apply Bidirectional LSTM over embedded inputs\n",
    "lstm_outs = keras.layers.wrappers.Bidirectional(\n",
    "    keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
    ")(embedded_inputs)\n",
    "\n",
    "# Apply dropout to LSTM outputs to prevent overfitting\n",
    "lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
    "\n",
    "# Attention Mechanism - Generate attention vectors\n",
    "input_dim = int(lstm_outs.shape[2])\n",
    "permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
    "attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
    "attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
    "attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
    "attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
    "\n",
    "# Last layer: fully connected with softmax activation\n",
    "fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
    "output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
    "\n",
    "# Finally building model\n",
    "model = keras.Model(inputs=[sequence_input], outputs=output)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "18000/18000 [==============================] - 698s 39ms/step - loss: 0.6677 - accuracy: 0.7343 - val_loss: 0.5904 - val_accuracy: 0.7675\n",
      "Epoch 2/5\n",
      "18000/18000 [==============================] - 822s 46ms/step - loss: 0.4847 - accuracy: 0.8106 - val_loss: 0.5555 - val_accuracy: 0.7780\n",
      "Epoch 3/5\n",
      "18000/18000 [==============================] - 694s 39ms/step - loss: 0.3829 - accuracy: 0.8539 - val_loss: 0.6268 - val_accuracy: 0.7665\n",
      "Epoch 4/5\n",
      "18000/18000 [==============================] - 688s 38ms/step - loss: 0.3026 - accuracy: 0.8845 - val_loss: 0.7012 - val_accuracy: 0.7500\n",
      "Epoch 5/5\n",
      "18000/18000 [==============================] - 710s 39ms/step - loss: 0.2265 - accuracy: 0.9149 - val_loss: 0.8138 - val_accuracy: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7bc6f72cf8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=5, batch_size=64, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "y_pred = pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=['Non-Factual', 'Non-imp Factual', 'Factual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Non-Factual       0.38      0.32      0.35       280\n",
      "Non-imp Factual       0.62      0.46      0.53       661\n",
      "        Factual       0.77      0.87      0.82      1560\n",
      "\n",
      "    avg / total       0.69      0.70      0.69      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
